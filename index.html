<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Job Interview Practice – Voice Only</title>
  <style>
    body{
      font-family: Arial, sans-serif;
      display:flex;
      flex-direction:column;
      align-items:center;
      justify-content:center;
      height:100vh;
      margin:0;
      background:#f5f5f5;
      gap:14px;
      padding: 18px;
      box-sizing: border-box;
    }

    #controls{
      display:flex;
      gap:10px;
      align-items:center;
      flex-wrap: wrap;
      justify-content:center;
    }

    button{
      font-size:1.1rem;
      padding:12px 20px;
      border:none;
      border-radius:10px;
      background:#0078d4;
      color:white;
      cursor:pointer;
    }
    button:active{ background:#005a9e; }
    button:disabled{ opacity:.7; cursor:not-allowed; }

    #status{
      font-size:.95rem;
      color:#333;
      background:#fff;
      border:1px solid #ddd;
      padding:10px 14px;
      border-radius:10px;
      max-width:920px;
      width:min(920px, 100%);
      box-shadow:0 2px 8px rgba(0,0,0,.05);
    }

    #chatWrap{
      max-width: 920px;
      width: min(920px, 100%);
      background:#fff;
      border:1px solid #ddd;
      border-radius: 12px;
      box-shadow:0 2px 8px rgba(0,0,0,.05);
      overflow:hidden;
    }

    #chatHeader{
      display:flex;
      justify-content:space-between;
      align-items:center;
      padding:10px 12px;
      border-bottom:1px solid #eee;
      background:#fafafa;
      font-size: .95rem;
      color:#333;
    }

    #chat{
      height: 46vh;
      min-height: 260px;
      max-height: 520px;
      overflow-y: auto;       /* scrollable */
      scroll-behavior: smooth;/* smooth scrolling */
      padding: 12px;
      display:flex;
      flex-direction:column;
      gap:10px;
    }

    .msg{
      padding: 10px 12px;
      border-radius: 12px;
      max-width: 85%;
      line-height: 1.35;
      white-space: pre-wrap;
      word-wrap: break-word;
    }

    .student{
      align-self:flex-start;
      background:#f0f6ff;
      border:1px solid #d6e8ff;
    }

    .bot{
      align-self:flex-end;
      background:#f4f4f4;
      border:1px solid #e6e6e6;
    }

    .meta{
      font-size: .8rem;
      color:#666;
      margin-top: 4px;
    }

    .row{
      display:flex;
      flex-direction:column;
      gap:2px;
    }

    #speedBox{
      display:flex;
      align-items:center;
      gap:8px;
      color:#333;
      background:#fff;
      border:1px solid #ddd;
      border-radius: 10px;
      padding:10px 12px;
      box-shadow:0 2px 8px rgba(0,0,0,.05);
      max-width: 920px;
      width:min(920px, 100%);
      justify-content:center;
      flex-wrap: wrap;
    }

    input[type="range"]{
      width: 200px;
    }

    code{
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", monospace;
      font-size:.92rem;
    }
  </style>
</head>

<body>

  <div id="controls">
    <button id="startBtn">Start Talking</button>
    <button id="copyBtn" title="Copy the full transcript">Copy Chat</button>
  </div>

  <div id="speedBox">
    <strong>Voice speed:</strong>
    <input id="speed" type="range" min="0.75" max="1.15" step="0.05" value="0.90">
    <span><code id="speedVal">0.90×</code></span>
    <span class="meta">(Lower = slower)</span>
  </div>

  <div id="status"><strong>Status:</strong> Ready.</div>

  <div id="chatWrap">
    <div id="chatHeader">
      <span><strong>Chat</strong> (keeps a running transcript)</span>
      <span class="meta">Tip: click Start → speak → click again</span>
    </div>
    <div id="chat" aria-live="polite" role="log"></div>
  </div>

  <script>
    // -----------------------------
    // 1) SYSTEM PROMPT (already says "Speak only in English.")
    // -----------------------------
    const systemPrompt = `
You are a supportive conversation partner for 9th-grade multilingual learners at WIDA Level 2. You are speaking one-on-one with a student about a job or career they researched. The student will speak their responses aloud, so expect short or simple answers.

Your overall job is to keep the conversation natural, warm, and curious. Speak the way a patient, engaging teacher would: clear, human, and interested, but never fake or overly enthusiastic.

Your goals:
- Help the student explain their ideas about the career they chose.
- Ask meaningful follow-up questions that feel like a normal conversation.
- Keep language accessible but not childish; use 9th-grade vocabulary.
- Encourage deeper thinking, including gentle challenges when appropriate.
- Support academic English by using academic language naturally and offering light language support (e.g., suggesting connectors like “because” or “for example”).
- Do NOT give sentence frames unless the student clearly asks for help or says they don’t know what to say.

Sentence frame rule:
Only provide a sentence frame if the student says something like:
“I don’t know,” “I need help,” “I don’t know how to say it,” or “I’m not sure what to say.”
When this happens, offer ONE simple sentence frame and ONE short example answer that sounds like a real student.

Tone:
Friendly, calm, conversational. Encouraging but not overly enthusiastic. Acknowledge interesting ideas without overpraising. Correct misunderstandings gently. Speak only in English.

Response format:
- Speak in 1–3 sentences unless a slightly longer answer feels natural.
- Ask one clear follow-up question every turn.
- You may suggest one helpful academic language element (e.g., “because,” “for example,” “one reason…”).
- Only include a sentence frame when the student explicitly asks for help.
- When giving a sentence frame, include one short example answer.

Start the conversation by asking:
“What job or career did you choose to research?”
`.trim();

    // -----------------------------
    // 2) CLIENT MEMORY (sent to Worker)
    // -----------------------------
    const messages = [];

    // -----------------------------
    // 3) UI ELEMENTS + HELPERS
    // -----------------------------
    const btn = document.getElementById("startBtn");
    const copyBtn = document.getElementById("copyBtn");
    const statusEl = document.getElementById("status");
    const chatEl = document.getElementById("chat");
    const speedEl = document.getElementById("speed");
    const speedValEl = document.getElementById("speedVal");

    function setStatus(msg) {
      statusEl.innerHTML = `<strong>Status:</strong> ${msg}`;
      console.log("[STATUS]", msg);
    }

    function escapeHtml(str) {
      return String(str).replace(/[&<>"']/g, s => ({
        "&": "&amp;",
        "<": "&lt;",
        ">": "&gt;",
        '"': "&quot;",
        "'": "&#039;"
      }[s]));
    }

    function nowTime() {
      const d = new Date();
      return d.toLocaleTimeString([], { hour: "2-digit", minute: "2-digit" });
    }

    function addChat(role, text) {
      const wrapper = document.createElement("div");
      wrapper.className = "row";

      const bubble = document.createElement("div");
      bubble.className = `msg ${role === "student" ? "student" : "bot"}`;
      bubble.innerHTML = escapeHtml(text);

      const meta = document.createElement("div");
      meta.className = "meta";
      meta.textContent = `${role === "student" ? "Student" : "CoachBot"} • ${nowTime()}`;

      wrapper.dataset.role = role === "student" ? "Student" : "CoachBot";
      wrapper.dataset.time = nowTime();

      wrapper.appendChild(bubble);
      wrapper.appendChild(meta);
      chatEl.appendChild(wrapper);

      chatEl.scrollTop = chatEl.scrollHeight; // keep latest visible
    }

    // Build a plain-text export of the entire chat
    function buildChatTranscript() {
      const rows = Array.from(chatEl.querySelectorAll(".row"));
      if (!rows.length) return "";

      const lines = rows.map(row => {
        const role = row.dataset.role || "Speaker";
        const time = row.dataset.time || "";
        const bubble = row.querySelector(".msg");
        const div = document.createElement("div");
        div.innerHTML = bubble ? bubble.innerHTML : "";
        const text = (div.textContent || "").trim();
        return `${role} [${time}]: ${text}`;
      });

      return lines.join("\n");
    }

    // Copy helper with fallback
    async function copyTextToClipboard(text) {
      if (!text) throw new Error("There is no chat content to copy yet.");
      if (navigator.clipboard && window.isSecureContext) {
        await navigator.clipboard.writeText(text);
        return;
      }
      const ta = document.createElement("textarea");
      ta.value = text;
      ta.style.position = "fixed";
      ta.style.left = "-9999px";
      ta.setAttribute("readonly", "");
      document.body.appendChild(ta);
      ta.select();
      try {
        document.execCommand("copy");
      } finally {
        document.body.removeChild(ta);
      }
    }

    // -----------------------------
    // 4) RECORDING STATE
    // -----------------------------
    let mediaRecorder = null;
    let audioChunks = [];
    let isRecording = false;
    let stream = null;

    // Track currently playing audio so the speed slider can affect it live
    let currentAudio = null;

    function blobToBase64(blob) {
      return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onloadend = () => resolve(String(reader.result).split(",")[1]);
        reader.onerror = reject;
        reader.readAsDataURL(blob);
      });
    }

    async function startRecording() {
      setStatus("Requesting microphone permission…");
      stream = await navigator.mediaDevices.getUserMedia({ audio: true });

      let options = { mimeType: "audio/webm; codecs=opus" };
      if (!MediaRecorder.isTypeSupported(options.mimeType)) options = { mimeType: "audio/webm" };
      if (options.mimeType && !MediaRecorder.isTypeSupported(options.mimeType)) options = {};

      mediaRecorder = new MediaRecorder(stream, options);
      audioChunks = [];

      mediaRecorder.ondataavailable = (e) => {
        if (e.data && e.data.size > 0) audioChunks.push(e.data);
      };

      mediaRecorder.start();
      isRecording = true;
      btn.innerText = "Listening…";
      setStatus(`Listening… click again to stop. <code>${options.mimeType || "default"}</code>`);
    }

    async function stopRecordingAndSend() {
      btn.innerText = "Processing…";
      btn.disabled = true;
      setStatus("Stopping recording…");

      return new Promise((resolve) => {
        mediaRecorder.addEventListener("stop", async () => {
          try {
            if (stream) {
              stream.getTracks().forEach(t => t.stop());
              stream = null;
            }

            const audioBlob = new Blob(audioChunks, { type: "audio/webm" });
            setStatus(`Captured audio: <code>${audioBlob.size}</code> bytes`);
            if (audioBlob.size < 800) throw new Error("Audio too small. Speak longer/louder.");

            const audio_base64 = await blobToBase64(audioBlob);

            setStatus("Sending to Cloudflare Worker (Workers AI)…");
            const response = await fetch("https://cool-field-e495.kboydmorton.workers.dev/", {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({
                audio_base64,
                mime_type: "audio/webm",
                system: systemPrompt,
                messages
              })
            });

            if (!response.ok) {
              const text = await response.text();
              throw new Error(`Worker error ${response.status}: ${text}`);
            }

            const result = await response.json();

            // Update memory + persistent chat log
            if (result.transcript) {
              messages.push({ role: "user", content: result.transcript });
              addChat("student", result.transcript);
            }
            if (result.assistant_text) {
              messages.push({ role: "assistant", content: result.assistant_text });
              addChat("bot", result.assistant_text);
            }

            setStatus("Playing response…");

            // Play returned MP3 (MeloTTS)
            const mime = result.audio_mime || "audio/mpeg";
            const audio = new Audio(`data:${mime};base64,${result.audio_base64}`);
            currentAudio = audio;

            // Apply speed
            const rate = parseFloat(speedEl.value) || 1.0;
            audio.playbackRate = rate;
            audio.defaultPlaybackRate = rate;

            // (Optional) keep pitch natural when supported
            try { audio.preservesPitch = true; } catch (e) {}
            try { audio.mozPreservesPitch = true; } catch (e) {}
            try { audio.webkitPreservesPitch = true; } catch (e) {}

            await audio.play();

            audio.onended = () => {
              currentAudio = null;
              btn.innerText = "Start Talking";
              btn.disabled = false;
              isRecording = false;
              setStatus("Ready.");
              resolve();
            };

          } catch (err) {
            console.error(err);
            currentAudio = null;
            btn.innerText = "Start Talking";
            btn.disabled = false;
            isRecording = false;
            setStatus(`❌ ${escapeHtml(err.message)} (see console)`);
            resolve();
          }
        }, { once: true });

        try {
          if (mediaRecorder && mediaRecorder.state === "recording") {
            mediaRecorder.requestData();
            mediaRecorder.stop();
          }
        } catch (err) {
          console.error(err);
          currentAudio = null;
          btn.innerText = "Start Talking";
          btn.disabled = false;
          isRecording = false;
          setStatus(`❌ Stop error: ${escapeHtml(err.message)}`);
          resolve();
        }
      });
    }

    // -----------------------------
    // 5) EVENTS
    // -----------------------------
    btn.addEventListener("click", async () => {
      try {
        if (!isRecording) {
          await startRecording();
        } else {
          await stopRecordingAndSend();
        }
      } catch (err) {
        console.error(err);
        currentAudio = null;
        btn.innerText = "Start Talking";
        btn.disabled = false;
        isRecording = false;
        setStatus(`❌ ${escapeHtml(err.message)} (see console)`);
      }
    });

    // Copy entire chat transcript
    copyBtn.addEventListener("click", async () => {
      try {
        const transcript = buildChatTranscript();
        await copyTextToClipboard(transcript);
        setStatus("Copied chat transcript to clipboard.");
      } catch (err) {
        console.error(err);
        setStatus(`❌ Copy failed: ${escapeHtml(err.message)}`);
      }
    });

    // Live speed updates during playback
    speedEl.addEventListener("input", () => {
      const rate = parseFloat(speedEl.value);
      speedValEl.textContent = `${rate.toFixed(2)}×`;
      if (currentAudio) {
        currentAudio.playbackRate = rate;
        currentAudio.defaultPlaybackRate = rate;
        console.log("Updated playbackRate to:", rate);
      }
    });

    // Optional: show initial bot prompt in chat log (text only)
    addChat("bot", "What job or career did you choose to research?");
  </script>
</body>
</html>
