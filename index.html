<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Job Interview Practice – Voice Only</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      height: 100vh;
      margin: 0;
      background: #f5f5f5;
      gap: 16px;
    }

    button {
      font-size: 1.5rem;
      padding: 20px 40px;
      border: none;
      border-radius: 12px;
      background: #0078d4;
      color: white;
      cursor: pointer;
    }

    button:active {
      background: #005a9e;
    }

    button:disabled {
      opacity: 0.7;
      cursor: not-allowed;
    }

    #startBtn {
      position: relative;
      z-index: 999999999 !important;
      pointer-events: auto !important;
    }

    body * {
      pointer-events: auto !important;
    }

    #status {
      font-size: 0.95rem;
      color: #333;
      background: #fff;
      border: 1px solid #ddd;
      padding: 10px 14px;
      border-radius: 10px;
      max-width: 720px;
      width: calc(100% - 48px);
      box-shadow: 0 2px 8px rgba(0,0,0,0.05);
    }

    #status code {
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", monospace;
      font-size: 0.9rem;
    }
  </style>
</head>

<body>
  <button id="startBtn">Start Talking</button>
  <div id="status"><strong>Status:</strong> Ready.</div>

  <script>
    // -----------------------------
    // 1. SYSTEM PROMPT FOR THE AGENT
    // -----------------------------
    const systemPrompt = `
You are a supportive conversation partner for 9th-grade multilingual learners at WIDA Level 2. You are speaking one-on-one with a student about a job or career they researched. The student will speak their responses aloud, so expect short or simple answers.

Your overall job is to keep the conversation natural, warm, and curious. Speak the way a patient, engaging teacher would: clear, human, and interested, but never fake or overly enthusiastic.

Your goals:
- Help the student explain their ideas about the career they chose.
- Ask meaningful follow-up questions that feel like a normal conversation.
- Keep language accessible but not childish; use 9th-grade vocabulary.
- Encourage deeper thinking, including gentle challenges when appropriate.
- Support academic English by using academic language naturally and offering light language support (e.g., suggesting connectors like “because” or “for example”).
- Do NOT give sentence frames unless the student clearly asks for help or says they don’t know what to say.

Sentence frame rule:
Only provide a sentence frame if the student says something like:
“I don’t know,” “I need help,” “I don’t know how to say it,” or “I’m not sure what to say.”
When this happens, offer ONE simple sentence frame and ONE short example answer that sounds like a real student.

Tone:
Friendly, calm, conversational. Encouraging but not overly enthusiastic. Acknowledge interesting ideas without overpraising. Correct misunderstandings gently. Speak only in English.

Response format:
- Speak in 1–3 sentences unless a slightly longer answer feels natural.
- Ask one clear follow-up question every turn.
- You may suggest one helpful academic language element (e.g., “because,” “for example,” “one reason…”).
- Only include a sentence frame when the student explicitly asks for help.
- When giving a sentence frame, include one short example answer.

Start the conversation by asking:
“What job or career did you choose to research?”
`;

    // -----------------------------
    // 2. TWO-CLICK VOICE LOOP (FIXED)
    // -----------------------------
    let mediaRecorder;
    let audioChunks = [];
    let isRecording = false;
    let stream = null;

    const btn = document.getElementById("startBtn");
    const statusEl = document.getElementById("status");

    function setStatus(msg) {
      statusEl.innerHTML = `<strong>Status:</strong> ${msg}`;
      console.log(msg);
    }

    // Convert Blob -> Base64 string (safe for JSON)
    function blobToBase64(blob) {
      return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onloadend = () => {
          // reader.result looks like: "data:audio/webm;base64,AAAA..."
          const base64 = String(reader.result).split(",")[1];
          resolve(base64);
        };
        reader.onerror = reject;
        reader.readAsDataURL(blob);
      });
    }

    async function startRecording() {
      try {
        setStatus("Requesting microphone access…");

        stream = await navigator.mediaDevices.getUserMedia({ audio: true });

        // Choose a supported mimeType
        let options = { mimeType: "audio/webm; codecs=opus" };
        if (!MediaRecorder.isTypeSupported(options.mimeType)) {
          options = { mimeType: "audio/webm" };
        }
        if (options.mimeType && !MediaRecorder.isTypeSupported(options.mimeType)) {
          options = {}; // default
        }

        setStatus(`Mic on. Recording format: <code>${options.mimeType || "default"}</code>`);

        mediaRecorder = new MediaRecorder(stream, options);
        audioChunks = [];

        mediaRecorder.ondataavailable = (e) => {
          if (e.data && e.data.size > 0) audioChunks.push(e.data);
        };

        mediaRecorder.onerror = (e) => {
          console.error("Recorder error:", e);
          setStatus("Recorder error. Check console for details.");
        };

        mediaRecorder.onstart = () => {
          setStatus("Listening… (click again to stop)");
        };

        mediaRecorder.start();
        isRecording = true;
        btn.innerText = "Listening…";
      } catch (err) {
        console.error(err);
        setStatus("Microphone blocked or unavailable. Check browser permissions.");
        btn.innerText = "Start Talking";
        isRecording = false;
      }
    }

    async function stopRecordingAndSend() {
      btn.innerText = "Processing…";
      btn.disabled = true;
      setStatus("Stopping recording…");

      return new Promise((resolve) => {
        mediaRecorder.addEventListener("stop", async () => {
          try {
            setStatus("Recording stopped. Preparing audio…");

            // IMPORTANT: stop the mic stream so the browser stops showing the mic icon
            if (stream) {
              stream.getTracks().forEach((t) => t.stop());
              stream = null;
            }

            const audioBlob = new Blob(audioChunks, { type: "audio/webm" });
            setStatus(`Audio captured: <code>${audioBlob.size}</code> bytes`);

            if (audioBlob.size < 500) {
              throw new Error("Audio blob is too small. No voice captured.");
            }

            const audio_base64 = await blobToBase64(audioBlob);

            setStatus("Sending audio to server…");

            const response = await fetch("https://cool-field-e495.kboydmorton.workers.dev/", {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({
                audio_base64,
                mime_type: "audio/webm",
                system: systemPrompt
              })
            });

            if (!response.ok) {
              const text = await response.text();
              throw new Error(`Server error ${response.status}: ${text}`);
            }

            const result = await response.json();

            if (!result.audio_base64) {
              throw new Error("Server did not return audio_base64.");
            }

            setStatus("Playing response…");

            const audio = new Audio("data:audio/wav;base64," + result.audio_base64);
            await audio.play();

            audio.onended = () => {
              setStatus("Ready.");
              btn.innerText = "Start Talking";
              btn.disabled = false;
              isRecording = false;
              resolve();
            };
          } catch (err) {
            console.error(err);
            setStatus(`Error: <code>${err.message}</code> (see console)`);
            btn.innerText = "Start Talking";
            btn.disabled = false;
            isRecording = false;
            resolve();
          }
        }, { once: true });

        try {
          // Helps ensure last audio chunk is captured before stopping
          if (mediaRecorder && mediaRecorder.state === "recording") {
            mediaRecorder.requestData();
            mediaRecorder.stop();
          }
        } catch (err) {
          console.error(err);
          setStatus(`Stop error: <code>${err.message}</code>`);
          btn.innerText = "Start Talking";
          btn.disabled = false;
          isRecording = false;
          resolve();
        }
      });
    }

    btn.onclick = async () => {
      if (!isRecording) {
        await startRecording();
      } else {
        await stopRecordingAndSend();
      }
    };
  </script>
</body>
</html>
``
