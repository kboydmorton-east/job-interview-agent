<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Job Interview Practice ‚Äì Voice Only</title>
  <style>
  body {
    font-family: Arial, sans-serif;
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    height: 100vh;
    margin: 0;
    background: #f5f5f5;
  }

  button {
    font-size: 1.5rem;
    padding: 20px 40px;
    border: none;
    border-radius: 12px;
    background: #0078d4;
    color: white;
    cursor: pointer;
  }

  button:active {
    background: #005a9e;
  }

  /* ‚≠ê These must be OUTSIDE button:active */
  #startBtn {
    position: relative;
    z-index: 999999999 !important;
    pointer-events: auto !important;
  }

  body * {
    pointer-events: auto !important;
  }
</style>
</head>

<body>
  <button id="startBtn">Start Talking</button>

  <script>
    // -----------------------------
    // 1. SYSTEM PROMPT FOR THE AGENT
    // -----------------------------
    const systemPrompt = `
You are a supportive conversation partner for 9th-grade multilingual learners at WIDA Level 2. You are speaking one-on-one with a student about a job or career they researched. The student will speak their responses aloud, so expect short or simple answers.

Your overall job is to keep the conversation natural, warm, and curious. Speak the way a patient, engaging teacher would: clear, human, and interested, but never fake or overly enthusiastic.

Your goals:
- Help the student explain their ideas about the career they chose.
- Ask meaningful follow-up questions that feel like a normal conversation.
- Keep language accessible but not childish; use 9th-grade vocabulary.
- Encourage deeper thinking, including gentle challenges when appropriate.
- Support academic English by using academic language naturally and offering light language support (e.g., suggesting connectors like ‚Äúbecause‚Äù or ‚Äúfor example‚Äù).
- Do NOT give sentence frames unless the student clearly asks for help or says they don‚Äôt know what to say.

Sentence frame rule:
Only provide a sentence frame if the student says something like:
‚ÄúI don‚Äôt know,‚Äù ‚ÄúI need help,‚Äù ‚ÄúI don‚Äôt know how to say it,‚Äù or ‚ÄúI‚Äôm not sure what to say.‚Äù
When this happens, offer ONE simple sentence frame and ONE short example answer that sounds like a real student.

Tone:
Friendly, calm, conversational. Encouraging but not overly enthusiastic. Acknowledge interesting ideas without overpraising. Correct misunderstandings gently. Speak only in English.

Response format:
- Speak in 1‚Äì3 sentences unless a slightly longer answer feels natural.
- Ask one clear follow-up question every turn.
- You may suggest one helpful academic language element (e.g., ‚Äúbecause,‚Äù ‚Äúfor example,‚Äù ‚Äúone reason‚Ä¶‚Äù).
- Only include a sentence frame when the student explicitly asks for help.
- When giving a sentence frame, include one short example answer.

Start the conversation by asking:
‚ÄúWhat job or career did you choose to research?‚Äù
`;

    // -----------------------------
    // 2. TWO-CLICK VOICE LOOP WITH MIME FIX
    // -----------------------------
  const systemPrompt = `... your exact prompt ...`;

  let mediaRecorder;
  let audioChunks = [];
  let isRecording = false;
  let stream; // ‚úÖ store the stream so we can stop the mic later

  const btn = document.getElementById("startBtn");

  function blobToBase64(blob) {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onloadend = () => {
        // reader.result is like: "data:audio/webm;base64,AAAA..."
        const base64 = reader.result.split(",")[1];
        resolve(base64);
      };
      reader.onerror = reject;
      reader.readAsDataURL(blob);
    });
  }

  async function startRecording() {
    stream = await navigator.mediaDevices.getUserMedia({ audio: true });

    // MIME TYPE FIX + FALLBACKS
    let options = { mimeType: "audio/webm; codecs=opus" };
    if (!MediaRecorder.isTypeSupported(options.mimeType)) options = { mimeType: "audio/webm" };
    if (options.mimeType && !MediaRecorder.isTypeSupported(options.mimeType)) options = {};

    mediaRecorder = new MediaRecorder(stream, options);
    audioChunks = [];

    mediaRecorder.ondataavailable = (e) => {
      if (e.data && e.data.size > 0) audioChunks.push(e.data);
    };

    mediaRecorder.onstart = () => console.log("‚úÖ recorder started");
    mediaRecorder.onerror = (e) => console.error("‚ùå recorder error", e);

    mediaRecorder.start();
    isRecording = true;
    btn.innerText = "Listening‚Ä¶";
  }

  async function stopRecordingAndSend() {
    btn.innerText = "Processing‚Ä¶";
    btn.disabled = true;

    return new Promise((resolve) => {
      mediaRecorder.addEventListener(
        "stop",
        async () => {
          try {
            console.log("‚úÖ recorder stopped");

            // ‚úÖ stop mic so it doesn't look like it keeps recording
            if (stream) {
              stream.getTracks().forEach((t) => t.stop());
              stream = null;
            }

            const audioBlob = new Blob(audioChunks, { type: "audio/webm" });
            console.log("üéß blob size:", audioBlob.size);

            // ‚úÖ convert to base64 for JSON transport
            const audio_base64 = await blobToBase64(audioBlob);

            const response = await fetch("https://cool-field-e495.kboydmorton.workers.dev/", {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({
                audio_base64,
                mime_type: "audio/webm",
                system: systemPrompt
              })
            });

            if (!response.ok) {
              const text = await response.text();
              throw new Error(`Server error ${response.status}: ${text}`);
            }

            const result = await response.json();
            console.log("‚úÖ worker result keys:", Object.keys(result));

            if (!result.audio_base64) {
              throw new Error("Worker did not return audio_base64.");
            }

            const audio = new Audio("data:audio/wav;base64," + result.audio_base64);
            await audio.play();

            audio.onended = () => {
              btn.innerText = "Start Talking";
              btn.disabled = false;
              isRecording = false;
              resolve();
            };
          } catch (err) {
            console.error("‚ùå processing error:", err);
            btn.innerText = "Start Talking";
            btn.disabled = false;
            isRecording = false;
            resolve();
          }
        },
        { once: true }
      );

      try {
        // ‚úÖ helps ensure final chunk is captured before stop
        if (mediaRecorder.state === "recording") mediaRecorder.requestData();
        mediaRecorder.stop();
      } catch (err) {
        console.error("‚ùå stop error:", err);
        btn.innerText = "Start Talking";
        btn.disabled = false;
        isRecording = false;
        resolve();
      }
    });
  }

  btn.onclick = async () => {
    if (!isRecording) {
      await startRecording();
    } else {
      await stopRecordingAndSend();
    }
  };
</script>
</body>
</html>


